typeof(MA_arboles)
MA_arboles <- as.matrix(MA_trees)
typeof(MA_arboles)
hi<-MA_arboles[, (1:14):=NULL]
install.packages(plyr)
install.packages('plyr')
MA_trees
rm(MA_Trees)
ddply(MA_trees, .(INVYR), summerize, TotalCarbon=sum(CARBON_AG))
library(plyr)
ddply(MA_trees, .(INVYR), summerize, TotalCarbon=sum(CARBON_AG))
ddply(MA_trees, .(INVYR), summarize, TotalCarbon=sum(CARBON_AG))
TotalCarbon
meow <- ddply(MA_trees, .(INVYR), summarize, TotalCarbon=sum(CARBON_AG))
View(meow)
colnames(meow)
meow <- ddply(MA_trees, .(INVYR), summarise, TotalCarbon=sum(CARBON_AG))
View(meow)
meow <- ddply(WA_trees, .(INVYR), summarise, TotalCarbon=sum(CARBON_AG))
View(meow)
meow <- ddply(MA_trees, .(INVYR), summarise, TotalCarbon=sum(CARBON_AG))
View(meow)
View(woof)
woof <- ddply(WA_trees, .(INVYR), summarise, TotalCarbon=sum(CARBON_AG))
View(woof)
meow <- ddply(MA_trees, .(INVYR), summarise, TotalCarbon=sum(CARBON_AG, na.rm=TRUE))
View(meow)
plot(meow)
plot(meow, pch=20, cex=0.5, col="blue")
plot(meow, pch=20, cex=0.5, col="aliceblue")
plot(meow, pch=20, cex=0.5, col="pink")
plot(meow, pch=20, cex=1.0, col="pink")
plot(meow, pch=20, cex=1.0, col="pink", lwd=0.5)
plot(meow, pch=20, cex=1.0, col="pink", lwd=0.5)
plot(meow, pch=20, cex=1.0, col="pink", lwd=0.5)
plot(meow, type="o", pch=20, cex=1.0, col="pink", )
plot(meow, type=1, pch=20, cex=1.0, col="pink", )
points(woof, pch=20, cex=1.0, col="olivegreen")
points(woof, pch=20, cex=1.0, col="olive")
points(woof, pch=20, cex=1.0, col="green")
plot(meow, pch=20, cex=1.0, col="pink" )
points(woof, pch=20, cex=1.0, col="green")
points(woof, pch=20, cex=1.0, col="green")
plot(woof, pch=20, cex=1.0, col="green" )
points(meow, pch=20, cex=1.0, col="red")
install.packages("plotly")
plot_ly(data = WA_trees, x = Sepal.Length, y = Petal.Length, mode = "markers")
library(plotly)
plot_ly(data = WA_trees, x = Sepal.Length, y = Petal.Length, mode = "markers")
WA_trees[,"INVYR"]
plot_ly(data = WA_trees, x = WA_trees[,"INVYR"], y = WA_trees[,"TotalCarbon"], mode = "markers")
colnames(WA_trees)
typeof(WA_trees)
plot_ly(data = woof, x = woof[,"INVYR"], y = woof[,"TotalCarbon"], mode = "markers")
#Anna M Calderon
#Matthew K Lau
#Harvard Forest
#gENM-Data Set Up
#Part 0
#8 July 2016
## Step 0. Set a working directory and File Paths
wd <- '../src'
setwd(wd)
## Step 1. Source Helpers Script
source("helpers.R")
## Step 2. Importing Climate Variables for NE
neClim <- stack("../data/neClim.grd")
## Step 3.  Getting climate change projections
# library(maptools)
# vepPolygon <- polygon_from_extent(raster::extent(xmin, xmax, ymin, ymax),
#                                   proj4string="+proj=longlat +ellps=WGS84 +datum=WGS84")
# IDs <- sapply(slot(vepPolygon, "polygons"), function(x) slot(x, "ID"))
# df <- data.frame(rep(0, length(IDs)), row.names=IDs)
# SPDFxx <- SpatialPolygonsDataFrame(vepPolygon, df)
# #tf <- tempfile()
# #writePolyShape(SPDFxx, tf)
# #getinfo.shape(tf)
#
# library(rgdal)
# ## shape <- readOGR('../data/neExtent',layer='neExtent')
# writeOGR(SPDFxx,dsn='../data/neExtent',layer='neExtent',driver='ESRI Shapefile',overwrite_layer=TRUE)
#
## Step 4. Downloading Species Presence Data
gspecies <- ''
prespoints <- read.csv('http://harvardforest.fas.harvard.edu/data/p14/hf147/hf147-13-antData_use4R_snappedToClim.csv')
if (gspecies == ''){gspecies <- "aphrud"}
colnames(prespoints) = c("spcode", "lon","lat")
gspecies <- prespoints[grep(gspecies,as.character(prespoints$spcode)),]
gspecies$spcode <- NULL
if (identical(colnames(gspecies),c( "lat", "lon"))){gspecies <- gspecies[,c('lon','lat')]}
if (is.matrix(gspecies) == FALSE){gspecies <- data.matrix(gspecies)}
## Step 5. Making Clusters and running gENMs
clust <- gClust(x=gspecies, p=neClim$bio1)
gENM(x=gspecies)
#Anna M Calderon
#Matthew K Lau
#Harvard Forest
#gENM-Data Set Up
#Part 0
#8 July 2016
## Step 0. Set a working directory and File Paths
wd <- '../src'
setwd(wd)
## Step 1. Source Helpers Script
source("helpers.R")
## Step 2. Importing Climate Variables for NE
neClim <- stack("../data/neClim.grd")
## Step 3.  Getting climate change projections
# library(maptools)
# vepPolygon <- polygon_from_extent(raster::extent(xmin, xmax, ymin, ymax),
#                                   proj4string="+proj=longlat +ellps=WGS84 +datum=WGS84")
# IDs <- sapply(slot(vepPolygon, "polygons"), function(x) slot(x, "ID"))
# df <- data.frame(rep(0, length(IDs)), row.names=IDs)
# SPDFxx <- SpatialPolygonsDataFrame(vepPolygon, df)
# #tf <- tempfile()
# #writePolyShape(SPDFxx, tf)
# #getinfo.shape(tf)
#
# library(rgdal)
# ## shape <- readOGR('../data/neExtent',layer='neExtent')
# writeOGR(SPDFxx,dsn='../data/neExtent',layer='neExtent',driver='ESRI Shapefile',overwrite_layer=TRUE)
#
## Step 4. Downloading Species Presence Data
gspecies <- ''
prespoints <- read.csv('http://harvardforest.fas.harvard.edu/data/p14/hf147/hf147-13-antData_use4R_snappedToClim.csv')
if (gspecies == ''){gspecies <- "aphrud"}
colnames(prespoints) = c("spcode", "lon","lat")
gspecies <- prespoints[grep(gspecies,as.character(prespoints$spcode)),]
gspecies$spcode <- NULL
if (identical(colnames(gspecies),c( "lat", "lon"))){gspecies <- gspecies[,c('lon','lat')]}
if (is.matrix(gspecies) == FALSE){gspecies <- data.matrix(gspecies)}
## Step 5. Making Clusters and running gENMs
clust <- gClust(x=gspecies, p=neClim$bio1)
gENM(x=gspecies)
source("helpers.R")
source('~/Desktop/gENM/src/helpers.R')
#Anna M Calderon
#Matthew K Lau
#Harvard Forest
#gENM-Data Set Up
#Part 0
#8 July 2016
## Step 0. Set a working directory and File Paths
wd <- '../src'
setwd(wd)
## Step 1. Source Helpers Script
source("helpers.R")
## Step 2. Importing Climate Variables for NE
neClim <- stack("../data/neClim.grd")
## Step 3.  Getting climate change projections
# library(maptools)
# vepPolygon <- polygon_from_extent(raster::extent(xmin, xmax, ymin, ymax),
#                                   proj4string="+proj=longlat +ellps=WGS84 +datum=WGS84")
# IDs <- sapply(slot(vepPolygon, "polygons"), function(x) slot(x, "ID"))
# df <- data.frame(rep(0, length(IDs)), row.names=IDs)
# SPDFxx <- SpatialPolygonsDataFrame(vepPolygon, df)
# #tf <- tempfile()
# #writePolyShape(SPDFxx, tf)
# #getinfo.shape(tf)
#
# library(rgdal)
# ## shape <- readOGR('../data/neExtent',layer='neExtent')
# writeOGR(SPDFxx,dsn='../data/neExtent',layer='neExtent',driver='ESRI Shapefile',overwrite_layer=TRUE)
#
## Step 4. Downloading Species Presence Data
gspecies <- ''
prespoints <- read.csv('http://harvardforest.fas.harvard.edu/data/p14/hf147/hf147-13-antData_use4R_snappedToClim.csv')
if (gspecies == ''){gspecies <- "aphrud"}
colnames(prespoints) = c("spcode", "lon","lat")
gspecies <- prespoints[grep(gspecies,as.character(prespoints$spcode)),]
gspecies$spcode <- NULL
if (identical(colnames(gspecies),c( "lat", "lon"))){gspecies <- gspecies[,c('lon','lat')]}
if (is.matrix(gspecies) == FALSE){gspecies <- data.matrix(gspecies)}
## Step 5. Making Clusters and running gENMs
clust <- gClust(x=gspecies, p=neClim$bio1)
gENM(x=gspecies)
wd <- '../src'
setwd(wd)
library(geoknife)
stencil <- webgeom()
stencil
query(stencil, 'geoms')
?webgeom
query('webdata')
library(geoknife)
stencil <- webgeom()
query(stencil,'geoms')
geom(stencil) <- 'sample:CONUS_Climate_Divisions'
query(stencil, 'attributes')
attribute(stencil) <- 'NAME'
query(stencil, 'values')
values(stencil) <- 'EAST CENTRAL MOUNTAINS'
query('webdata')
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future')
query(fabric,'variables')
variables(fabric) <- 'tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85'
query(fabric,'times')
times(fabric) <- c('2006-01-01', '2007-01-01')
job <- geoknife(stencil, fabric, wait=TRUE)
data.out <- result(job, with.units=TRUE)
data.out
colnames(data.out)
typeof(data.out)
plot(data.out$variable)
plot(data.out$`EAST CENTRAL MOUNTAINS`)
rasterImage(data.out$`EAST CENTRAL MOUNTAINS`)
data.out[1,]
?result
library(geoknife)
stencil <- webgeom()
query(stencil,'geoms')
geom(stencil) <- 'sample:CONUS_Climate_Divisions'
query(stencil, 'attributes')
attribute(stencil) <- 'NAME'
query(stencil, 'values')
values(stencil) <- 'EAST CENTRAL MOUNTAINS'
query('webdata')
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future')
query(fabric,'variables')
variables(fabric) <- 'tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85'
query(fabric,'times')
times(fabric) <- c('2006-01-01', '2006-03-01')
job <- geoknife(stencil, fabric, wait=TRUE)
data.out <- result(job, with.units=TRUE)
data.out
library(geoknife)
stencil <- webgeom()
query(stencil,'geoms')
geom(stencil) <- 'sample:CONUS_Climate_Divisions'
query(stencil, 'attributes')
attribute(stencil) <- 'NAME'
query(stencil, 'values')
values(stencil) <- 'EAST CENTRAL MOUNTAINS'
query('webdata')
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future')
query(fabric,'variables')
variables(fabric) <- 'tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85'
query(fabric,'times')
times(fabric) <- c('2006-01-01', '2006-03-01')
?job
?geoknife
job <- geoknife(stencil, fabric, wait = TRUE, OUTPUT_TYPE = "geotiff")
?webprocess
?fabric
library(geoknife)
library(geoknife)
knife <- webprocess(algorithm = list('OPeNDAP Subset'="gov.usgs.cida.gdp.wps.
algorithm.FeatureCoverageOPeNDAPIntersectionAlgorithm"))
webprocess()
?webprocess
knife <- webprocess()
query(knife, 'algorithms')
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future')
stencil <- simplegeom(data.frame('point1' = c(-73,41), 'point2' = c(-66.95833,-47.45833)))
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future',
variable='tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85',times=c('2014-07-15','2014-07-18'))
stencil <- simplegeom(data.frame('point1' = c(-73,41), 'point2' = c(-66.95833,-47.45833)))
job <- geoknife(stencil, fabric, knife, wait = TRUE, OUTPUT_TYPE = "geotiff")
?OUTPUT_TYPE
job <- geoknife(stencil, fabric, knife, wait = TRUE)
download(job, destination = file.path(tempdir(), 'geoknife_data.zip'), overwrite=TRUE)
download(job, destination = "/Users/annacalderon/Desktop/geoknife_data.zip", overwrite=TRUE)
unzip(file, exdir=file.path(tempdir(),'NASA'))
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm")
email = 'acalderon@ucmerced.edu')
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm")
email = acalderon@ucmerced.edu)
knife <- webprocess(email = 'acalderon@ucmerced.edu')
knife
knife <- webprocess(wait = TRUE)
knife
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(email = 'acalderon@ucmerced.edu')
knife <- webprocess(wait = TRUE)
knife
knife <- webprocess(email = 'acalderon@ucmerced.edu')
knife
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(wait = TRUE)
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
stencil <- webgeom('state::Rhode Island, Massachusetts, Maine, Vermont, Connecticut, New Hampshire')
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
job <- geoknife(stencil, fabric, knife, wait = TRUE, OUTPUT_TYPE="geotiff")
check(job)
download(job, destination = "/Users/annacalderon/Desktop/", overwrite=TRUE)
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(email = 'acalderon@ucmerced.edu')
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future',
variable='tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85',times=c('2014-07-15','2014-07-18'))
stencil <- webgeom('state::Rhode Island, Massachusetts, Maine, Vermont, Connecticut, New Hampshire')
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(wait = TRUE)
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future',
variable='tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85',times=c('2014-07-15','2014-07-18'))
stencil <- webgeom('state::Rhode Island, Massachusetts, Maine, Vermont, Connecticut, New Hampshire')
job <- geoknife(stencil, fabric, knife, wait = TRUE)
download(job, destination = "/Users/annacalderon/Desktop/", overwrite=TRUE)
download(job, destination = "/Users/annacalderon/Desktop", overwrite=TRUE)
check(job)
geom(stencil) <- "derivative:CONUS_States"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Maine", "Vermont", "Connecticut", "New Hampshire")
stencil
geom(stencil) <- "sample:CONUS_Climate_Divisions""
geom(stencil) <- "sample:CONUS_Climate_Divisions")
geom(stencil) <- "sample:CONUS_Climate_Divisions"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Maine", "Vermont", "Connecticut", "New Hampshire")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
geom(stencil) <- "sample:CONUS_Climate_Divisions"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
geom(stencil) <- "sample:CONUS_Climate_Divisions"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Maine")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
geom(stencil) <- "sample:CONUS_Climate_Divisions"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Vermont", "Connecticut")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
values(stencil) <- c("Maine")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
geom(stencil) <- "sample:CONUS_Climate_Divisions")
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Vermont", "Connecticut", "New Hampshire")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
data.out <- result(job, with.units=TRUE)
data.out
typeof(data.out)
knife <- webprocess(algorithm = list('OPeNDAP Subset'="gov.usgs.cida.gdp.wps.algorithm.FeatureCoverageOPeNDAPIntersectionAlgorithm"))
fabric <- webdata(url='dods://opendap.larc.nasa.gov/opendap/hyrax/SortByProduct/CERES/EBAF/Surface_Edition2.8/CERES_EBAF-Surface_Edition2.8_200003-201506.nc',
variable="sfc_sw_down_all_mon", #Surface Shortwave Flux Down, Monthly Means, All-Sky conditions
times=c('2014-07-15','2014-07-15'))
stencil <- simplegeom(data.frame('point1' = c(-5,32), 'point2' = c(-90,-78))) # big 'ol chunk 'o data
job <- geoknife(stencil, fabric, knife, wait = TRUE, OUTPUT_TYPE = "geotiff")
file <- download(job, destination = file.path(tempdir(), 'nasa_data.zip'), overwrite=TRUE)
job
file <- download(job, destination = file.path(tempdir(), 'nasa_data.zip'), overwrite=TRUE)
data.out <- result(job, with.units=TRUE)
job <- geoknife(stencil, fabric, knife, wait = TRUE)
library(geoknife)
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(wait = TRUE)
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future',
variable='tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85',times=c('2014-07-15','2014-07-18'))
geom(stencil) <- "sample:CONUS_Climate_Divisions")
geom(stencil) <- "sample:CONUS_Climate_Divisions"
geom(stencil) <- "sample:CONUS_Climate_Divisions"
library(geoknife)
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(wait = TRUE)
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future',
variable='tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85',times=c('2014-07-15','2014-07-18'))
geom(stencil) <- "sample:CONUS_Climate_Divisions"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Vermont", "Connecticut", "New Hampshire")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
rm(list=ls())
library(geoknife)
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(wait = TRUE)
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future',
variable='tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85',times=c('2014-07-15','2014-07-18'))
geom(stencil) <- "sample:CONUS_Climate_Divisions"
> library(raster)
str_name <- '/Users/annacalderon/Desktop/gENM/data/
library(raster)
library(raster)
str_name <- '/Users/annacalderon/Desktop/gENM/data/
cida.usgs.gov-thredds-dodsC-macav2metdata_daily_future-2099-07-01-00-00-00.tiff")
)
str_name <- '/Users/annacalderon/Desktop/gENM/data/
cida.usgs.gov-thredds-dodsC-macav2metdata_daily_future-2099-07-01-00-00-00.tiff')
str_name <- '/Users/annacalderon/Desktop/gENM/data/try.tiff"
str_name <- ('/Users/annacalderon/Desktop/gENM/data/try.tiff')
raster(str_name)
herewego <-raster(str_name)
plot(herewego)
library(raster)
str_name <- ('/Users/annacalderon/Desktop/gENM/data/try.tiff')
herewego <-raster(str_name)
herewego
plot(herewego)
wd <- '/Users/annacalderon/Desktop/gENM/src'
setwd(wd)
## Step 1. Source Helpers Script
source("helpers.R")
## Step 2. Importing Climate Variables for NE
neClim <- stack("../data/neClim.grd")
neClim
neClim@resolution
neClim$resolution
herewego
str_name <- ('/Users/annacalderon/Desktop/gENM/data/neng.tiff')
herewego <-raster(str_name)
plot(herewego)
data(stateMapEnv)
map("state", xlim=c(-73.70833, -66.95833), ylim=c(41, 47.45833), fill=T, col="honeydew", add=T)
plot(herewego)
wd <- '/Users/annacalderon/Desktop/gENM/src'
setwd(wd)
gspecies <- ''
prespoints <- read.csv('http://harvardforest.fas.harvard.edu/data/p14/hf147/hf147-13-antData_use4R_snappedToClim.csv')
if (gspecies == ''){gspecies <- "aphrud"}
colnames(prespoints) = c("spcode", "lon","lat")
gspecies <- prespoints[grep(gspecies,as.character(prespoints$spcode)),]
gspecies$spcode <- NULL
if (identical(colnames(gspecies),c( "lat", "lon"))){gspecies <- gspecies[,c('lon','lat')]}
if (is.matrix(gspecies) == FALSE){gspecies <- data.matrix(gspecies)}
MVNh = which(gspecies[,'lat'] >= 42.703589)
MVNh
library(raster)
str_name <- ('/Users/annacalderon/Desktop/gENM/data/NE.tiff')
herewego <-raster(str_name)
plot(herewego)
library(raster)
str_name <- ('/Users/annacalderon/Desktop/gENM/data/NE.tiff')
herewego <-raster(str_name)
plot(herewego)
herewego
mvnh = which(gspecies[,'lon']) <= -71.786109)
mvnh = which(gspecies[,'lon'] <= -71.786109)
mvnh
write.csv(gspecies)
write.csv(gspecies, file.path("/Users/annacalderon/Desktop/gENM/data/"))
write.csv(gspecies, file.path("/Users/annacalderon/Desktop/gENM/data/gspecies.csv"))
write.csv(gspecies, file.path("/Users/annacalderon/Desktop/Gspecies.csv"))
data(stateMapEnv)
plot(c(-73.70833, -66.95833), c(41, 47.45833), mar=par("mar"), xlab="longitude",
ylab="latitude", xaxt="n", yaxt="n", type="n", main="Presence and Absence Points")
rect(par("usr")[1],par("usr")[3],par("usr")[2],par("usr")[4], col="lightcyan")
map("state", xlim=c(-73.70833, -66.95833), ylim=c(41, 47.45833), fill=T, col="honeydew", add=T)
# plot the points
points(gspecies[,"lon"], gspecies[,"lat"], col="darkolivegreen4", pch=20, cex=0.5)
subset(gspecies, VNMn)
VNMn = which(gspecies[,'lat'] >= 42.703589)
subset(gspecies, VNMn)
subset(gspecies, which(gspecies[,'lat'] >= 42.703589))
typeof(gspecies)
?subset.matrix
is.matrix(gspecies)
stateMapEnv
typeof(stateMapEnv)
?map
?myborder
map("state")
?map
map("state", xlim=c(-73.70833, -66.95833), ylim=c(41, 47.45833), fill=T, col="honeydew", add=T, exact = TRUE)
?exact
subset.matrix(gspecies[,'lat'] >= 42.703589)
gspecies
gspecies[,-1]
GSPEC <-gspecies[,-1]
GSPEC
colnames(gspecies) = c("numb", "lon","lat")
colnames(gpecies)
colnames(gspecies)
colnames(gspecies)
prespoints <- read.csv('http://harvardforest.fas.harvard.edu/data/p14/hf147/hf147-13-antData_use4R_snappedToClim.csv')
if (gspecies == ''){gspecies <- "aphrud"}
gspecies <- ''
prespoints <- read.csv('http://harvardforest.fas.harvard.edu/data/p14/hf147/hf147-13-antData_use4R_snappedToClim.csv')
if (gspecies == ''){gspecies <- "aphrud"}
colnames(prespoints) = c("spcode", "lon","lat")
wd <- '/Users/annacalderon/Desktop/gENM/src'
setwd(wd)
## Step 1. Source Helpers Script
source("helpers.R")
## Step 2. Importing Climate Variables for NE
neClim <- stack("../data/neClim.grd")
## Step 3.  Getting climate change projections
# library(maptools)
# vepPolygon <- polygon_from_extent(raster::extent(xmin, xmax, ymin, ymax),
#                                   proj4string="+proj=longlat +ellps=WGS84 +datum=WGS84")
# IDs <- sapply(slot(vepPolygon, "polygons"), function(x) slot(x, "ID"))
# df <- data.frame(rep(0, length(IDs)), row.names=IDs)
# SPDFxx <- SpatialPolygonsDataFrame(vepPolygon, df)
# #tf <- tempfile()
# #writePolyShape(SPDFxx, tf)
# #getinfo.shape(tf)
#
# library(rgdal)
# ## shape <- readOGR('../data/neExtent',layer='neExtent')
# writeOGR(SPDFxx,dsn='../data/neExtent',layer='neExtent',driver='ESRI Shapefile',overwrite_layer=TRUE)
#
## Step 4. Downloading Species Presence Data
gspecies <- ''
prespoints <- read.csv('http://harvardforest.fas.harvard.edu/data/p14/hf147/hf147-13-antData_use4R_snappedToClim.csv')
if (gspecies == ''){gspecies <- "aphrud"}
colnames(prespoints) = c("spcode", "lon","lat")
