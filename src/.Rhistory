source('~/Desktop/gENM/src/helpers.R')
#Anna M Calderon
#Matthew K Lau
#Harvard Forest
#gENM-Data Set Up
#Part 0
#8 July 2016
## Step 0. Set a working directory and File Paths
wd <- '../src'
setwd(wd)
## Step 1. Source Helpers Script
source("helpers.R")
## Step 2. Importing Climate Variables for NE
neClim <- stack("../data/neClim.grd")
## Step 3.  Getting climate change projections
# library(maptools)
# vepPolygon <- polygon_from_extent(raster::extent(xmin, xmax, ymin, ymax),
#                                   proj4string="+proj=longlat +ellps=WGS84 +datum=WGS84")
# IDs <- sapply(slot(vepPolygon, "polygons"), function(x) slot(x, "ID"))
# df <- data.frame(rep(0, length(IDs)), row.names=IDs)
# SPDFxx <- SpatialPolygonsDataFrame(vepPolygon, df)
# #tf <- tempfile()
# #writePolyShape(SPDFxx, tf)
# #getinfo.shape(tf)
#
# library(rgdal)
# ## shape <- readOGR('../data/neExtent',layer='neExtent')
# writeOGR(SPDFxx,dsn='../data/neExtent',layer='neExtent',driver='ESRI Shapefile',overwrite_layer=TRUE)
#
## Step 4. Downloading Species Presence Data
gspecies <- ''
prespoints <- read.csv('http://harvardforest.fas.harvard.edu/data/p14/hf147/hf147-13-antData_use4R_snappedToClim.csv')
if (gspecies == ''){gspecies <- "aphrud"}
colnames(prespoints) = c("spcode", "lon","lat")
gspecies <- prespoints[grep(gspecies,as.character(prespoints$spcode)),]
gspecies$spcode <- NULL
if (identical(colnames(gspecies),c( "lat", "lon"))){gspecies <- gspecies[,c('lon','lat')]}
if (is.matrix(gspecies) == FALSE){gspecies <- data.matrix(gspecies)}
## Step 5. Making Clusters and running gENMs
clust <- gClust(x=gspecies, p=neClim$bio1)
gENM(x=gspecies)
wd <- '../src'
setwd(wd)
library(geoknife)
stencil <- webgeom()
stencil
query(stencil, 'geoms')
?webgeom
query('webdata')
library(geoknife)
stencil <- webgeom()
query(stencil,'geoms')
geom(stencil) <- 'sample:CONUS_Climate_Divisions'
query(stencil, 'attributes')
attribute(stencil) <- 'NAME'
query(stencil, 'values')
values(stencil) <- 'EAST CENTRAL MOUNTAINS'
query('webdata')
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future')
query(fabric,'variables')
variables(fabric) <- 'tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85'
query(fabric,'times')
times(fabric) <- c('2006-01-01', '2007-01-01')
job <- geoknife(stencil, fabric, wait=TRUE)
data.out <- result(job, with.units=TRUE)
data.out
colnames(data.out)
typeof(data.out)
plot(data.out$variable)
plot(data.out$`EAST CENTRAL MOUNTAINS`)
rasterImage(data.out$`EAST CENTRAL MOUNTAINS`)
data.out[1,]
?result
library(geoknife)
stencil <- webgeom()
query(stencil,'geoms')
geom(stencil) <- 'sample:CONUS_Climate_Divisions'
query(stencil, 'attributes')
attribute(stencil) <- 'NAME'
query(stencil, 'values')
values(stencil) <- 'EAST CENTRAL MOUNTAINS'
query('webdata')
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future')
query(fabric,'variables')
variables(fabric) <- 'tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85'
query(fabric,'times')
times(fabric) <- c('2006-01-01', '2006-03-01')
job <- geoknife(stencil, fabric, wait=TRUE)
data.out <- result(job, with.units=TRUE)
data.out
library(geoknife)
stencil <- webgeom()
query(stencil,'geoms')
geom(stencil) <- 'sample:CONUS_Climate_Divisions'
query(stencil, 'attributes')
attribute(stencil) <- 'NAME'
query(stencil, 'values')
values(stencil) <- 'EAST CENTRAL MOUNTAINS'
query('webdata')
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future')
query(fabric,'variables')
variables(fabric) <- 'tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85'
query(fabric,'times')
times(fabric) <- c('2006-01-01', '2006-03-01')
?job
?geoknife
job <- geoknife(stencil, fabric, wait = TRUE, OUTPUT_TYPE = "geotiff")
?webprocess
?fabric
library(geoknife)
library(geoknife)
knife <- webprocess(algorithm = list('OPeNDAP Subset'="gov.usgs.cida.gdp.wps.
algorithm.FeatureCoverageOPeNDAPIntersectionAlgorithm"))
webprocess()
?webprocess
knife <- webprocess()
query(knife, 'algorithms')
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future')
stencil <- simplegeom(data.frame('point1' = c(-73,41), 'point2' = c(-66.95833,-47.45833)))
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future',
variable='tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85',times=c('2014-07-15','2014-07-18'))
stencil <- simplegeom(data.frame('point1' = c(-73,41), 'point2' = c(-66.95833,-47.45833)))
job <- geoknife(stencil, fabric, knife, wait = TRUE, OUTPUT_TYPE = "geotiff")
?OUTPUT_TYPE
job <- geoknife(stencil, fabric, knife, wait = TRUE)
download(job, destination = file.path(tempdir(), 'geoknife_data.zip'), overwrite=TRUE)
download(job, destination = "/Users/annacalderon/Desktop/geoknife_data.zip", overwrite=TRUE)
unzip(file, exdir=file.path(tempdir(),'NASA'))
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm")
email = 'acalderon@ucmerced.edu')
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm")
email = acalderon@ucmerced.edu)
knife <- webprocess(email = 'acalderon@ucmerced.edu')
knife
knife <- webprocess(wait = TRUE)
knife
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(email = 'acalderon@ucmerced.edu')
knife <- webprocess(wait = TRUE)
knife
knife <- webprocess(email = 'acalderon@ucmerced.edu')
knife
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(wait = TRUE)
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
stencil <- webgeom('state::Rhode Island, Massachusetts, Maine, Vermont, Connecticut, New Hampshire')
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
job <- geoknife(stencil, fabric, knife, wait = TRUE, OUTPUT_TYPE="geotiff")
check(job)
download(job, destination = "/Users/annacalderon/Desktop/", overwrite=TRUE)
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(email = 'acalderon@ucmerced.edu')
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future',
variable='tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85',times=c('2014-07-15','2014-07-18'))
stencil <- webgeom('state::Rhode Island, Massachusetts, Maine, Vermont, Connecticut, New Hampshire')
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(wait = TRUE)
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future',
variable='tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85',times=c('2014-07-15','2014-07-18'))
stencil <- webgeom('state::Rhode Island, Massachusetts, Maine, Vermont, Connecticut, New Hampshire')
job <- geoknife(stencil, fabric, knife, wait = TRUE)
download(job, destination = "/Users/annacalderon/Desktop/", overwrite=TRUE)
download(job, destination = "/Users/annacalderon/Desktop", overwrite=TRUE)
check(job)
geom(stencil) <- "derivative:CONUS_States"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Maine", "Vermont", "Connecticut", "New Hampshire")
stencil
geom(stencil) <- "sample:CONUS_Climate_Divisions""
geom(stencil) <- "sample:CONUS_Climate_Divisions")
geom(stencil) <- "sample:CONUS_Climate_Divisions"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Maine", "Vermont", "Connecticut", "New Hampshire")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
geom(stencil) <- "sample:CONUS_Climate_Divisions"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
geom(stencil) <- "sample:CONUS_Climate_Divisions"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Maine")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
geom(stencil) <- "sample:CONUS_Climate_Divisions"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Vermont", "Connecticut")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
values(stencil) <- c("Maine")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
geom(stencil) <- "sample:CONUS_Climate_Divisions")
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Vermont", "Connecticut", "New Hampshire")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
data.out <- result(job, with.units=TRUE)
data.out
typeof(data.out)
knife <- webprocess(algorithm = list('OPeNDAP Subset'="gov.usgs.cida.gdp.wps.algorithm.FeatureCoverageOPeNDAPIntersectionAlgorithm"))
fabric <- webdata(url='dods://opendap.larc.nasa.gov/opendap/hyrax/SortByProduct/CERES/EBAF/Surface_Edition2.8/CERES_EBAF-Surface_Edition2.8_200003-201506.nc',
variable="sfc_sw_down_all_mon", #Surface Shortwave Flux Down, Monthly Means, All-Sky conditions
times=c('2014-07-15','2014-07-15'))
stencil <- simplegeom(data.frame('point1' = c(-5,32), 'point2' = c(-90,-78))) # big 'ol chunk 'o data
job <- geoknife(stencil, fabric, knife, wait = TRUE, OUTPUT_TYPE = "geotiff")
file <- download(job, destination = file.path(tempdir(), 'nasa_data.zip'), overwrite=TRUE)
job
file <- download(job, destination = file.path(tempdir(), 'nasa_data.zip'), overwrite=TRUE)
data.out <- result(job, with.units=TRUE)
job <- geoknife(stencil, fabric, knife, wait = TRUE)
library(geoknife)
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(wait = TRUE)
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future',
variable='tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85',times=c('2014-07-15','2014-07-18'))
geom(stencil) <- "sample:CONUS_Climate_Divisions")
geom(stencil) <- "sample:CONUS_Climate_Divisions"
geom(stencil) <- "sample:CONUS_Climate_Divisions"
library(geoknife)
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(wait = TRUE)
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future',
variable='tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85',times=c('2014-07-15','2014-07-18'))
geom(stencil) <- "sample:CONUS_Climate_Divisions"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Vermont", "Connecticut", "New Hampshire")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
rm(list=ls())
library(geoknife)
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(wait = TRUE)
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future',
variable='tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85',times=c('2014-07-15','2014-07-18'))
geom(stencil) <- "sample:CONUS_Climate_Divisions"
> library(raster)
str_name <- '/Users/annacalderon/Desktop/gENM/data/
library(raster)
library(raster)
str_name <- '/Users/annacalderon/Desktop/gENM/data/
cida.usgs.gov-thredds-dodsC-macav2metdata_daily_future-2099-07-01-00-00-00.tiff")
)
str_name <- '/Users/annacalderon/Desktop/gENM/data/
cida.usgs.gov-thredds-dodsC-macav2metdata_daily_future-2099-07-01-00-00-00.tiff')
str_name <- '/Users/annacalderon/Desktop/gENM/data/try.tiff"
str_name <- ('/Users/annacalderon/Desktop/gENM/data/try.tiff')
raster(str_name)
herewego <-raster(str_name)
plot(herewego)
wd <- '/Users/annacalderon/Desktop/gENM/src'
setwd(wd)
## Step 1. Source Helpers Script
source("helpers.R")
## Step 2. Importing Climate Variables for NE
neClim <- stack("../data/neClim.grd")
## Step 3.  Getting climate change projections
# library(maptools)
# vepPolygon <- polygon_from_extent(raster::extent(xmin, xmax, ymin, ymax),
#                                   proj4string="+proj=longlat +ellps=WGS84 +datum=WGS84")
# IDs <- sapply(slot(vepPolygon, "polygons"), function(x) slot(x, "ID"))
# df <- data.frame(rep(0, length(IDs)), row.names=IDs)
# SPDFxx <- SpatialPolygonsDataFrame(vepPolygon, df)
# #tf <- tempfile()
# #writePolyShape(SPDFxx, tf)
# #getinfo.shape(tf)
#
# library(rgdal)
# ## shape <- readOGR('../data/neExtent',layer='neExtent')
# writeOGR(SPDFxx,dsn='../data/neExtent',layer='neExtent',driver='ESRI Shapefile',overwrite_layer=TRUE)
#
## Step 4. Downloading Species Presence Data
gspecies <- ''
prespoints <- read.csv('http://harvardforest.fas.harvard.edu/data/p14/hf147/hf147-13-antData_use4R_snappedToClim.csv')
if (gspecies == ''){gspecies <- "aphrud"}
colnames(prespoints) = c("spcode", "lon","lat")
colnames(prespoints) = c("spcode", "lon","lat")
if (gspecies == ''){gspecies <- "aphrud"}
prespoints
us <- getData("GADM", country="USA", level=1)
nestates <- c("Maine", "Vermont", "Massachusetts", "New Hampshire" ,"Connecticut",
"Rhode Island")
ne = us[match(toupper(nestates),toupper(us$NAME_1)),]
r = raster(xmn=-85,xmx=-65,ymn=36,ymx=48,nrow=100,ncol=100)
r[]=runif(100*100)
plot(r)
plot(ne,add=TRUE)
state <- readOGR(dsn = path.data, layer = "usa_state_shapefile")
projection(state) <- CRS("+proj=longlat +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +no_defs")
readOGR
?readOGR
state <- readOGR(dsn = "/Users/annacalderon/Desktop/gENM/data", layer = "usa_state_shapefile")
state <- readOGR(dsn = "/Users/annacalderon/Desktop/gENM/data/usamap", layer = "usa_state_shapefile")
library(rgdal)
library(raster)
?readOGR
library(raster)
# use state bounds from gadm website:
# us = shapefile("USA_adm1.shp")
us <- getData("GADM", country="USA", level=1)
# extract states (need to uppercase everything)
nestates <- c("Maine", "Vermont", "Massachusetts", "New Hampshire" ,"Connecticut",
"Rhode Island","New York","Pennsylvania", "New Jersey",
"Maryland", "Delaware", "Virginia", "West Virginia")
ne = us[match(toupper(nestates),toupper(us$NAME_1)),]
# create a random raster over the space:
r = raster(xmn=-85,xmx=-65,ymn=36,ymx=48,nrow=100,ncol=100)
r[]=runif(100*100)
# plot it with the boundaries we want to clip against:
plot(r)
plot(ne,add=TRUE)
# now use the mask function
rr <- mask(r, ne)
# plot, and overlay:
plot(rr);plot(ne,add=TRUE)
us <- getData("GADM", country="USA", level=1)
# extract states (need to uppercase everything)
nestates <- c("Maine", "Vermont", "Massachusetts", "New Hampshire" ,"Connecticut",
"Rhode Island")
ne = us[match(toupper(nestates),toupper(us$NAME_1)),]
# create a random raster over the space:
r = raster(xmn=-85,xmx=-65,ymn=36,ymx=48,nrow=100,ncol=100)
r[]=runif(100*100)
# plot it with the boundaries we want to clip against:
plot(r)
plot(ne,add=TRUE)
# now use the mask function
rr <- mask(r, ne)
# plot, and overlay:
plot(rr);plot(ne,add=TRUE)
prespoints <- read.csv('http://harvardforest.fas.harvard.edu/data/p14/hf147/hf147-13-antData_use4R_snappedToClim.csv')
if (gspecies == ''){gspecies <- "aphrud"}
wd <- '/Users/annacalderon/Desktop/gENM/src'
setwd(wd)
## Step 1. Source Helpers Script
source("helpers.R")
## Step 2. Importing Climate Variables for NE
neClim <- stack("../data/neClim.grd")
gspecies <- ''
prespoints <- read.csv('http://harvardforest.fas.harvard.edu/data/p14/hf147/hf147-13-antData_use4R_snappedToClim.csv')
if (gspecies == ''){gspecies <- "aphrud"}
colnames(prespoints) = c("spcode", "lon","lat")
gspecies <- prespoints[grep(gspecies,as.character(prespoints$spcode)),]
gspecies$spcode <- NULL
if (identical(colnames(gspecies),c( "lat", "lon"))){gspecies <- gspecies[,c('lon','lat')]}
if (is.matrix(gspecies) == FALSE){gspecies <- data.matrix(gspecies)}
points(gspecies, col="darkolivegreen4", pch=20, cex=0.5)
library(raster)
# use state bounds from gadm website:
# us = shapefile("USA_adm1.shp")
us <- getData("GADM", country="USA", level=1)
# extract states (need to uppercase everything)
nestates <- c("Maine", "Vermont", "Massachusetts", "New Hampshire" ,"Connecticut",
"Rhode Island")
ne = us[match(toupper(nestates),toupper(us$NAME_1)),]
points(gspecies, col="darkolivegreen4", pch=20, cex=0.5)
# create a random raster over the space:
#r = raster(xmn=-85,xmx=-65,ymn=36,ymx=48,nrow=100,ncol=100)
#r[]=runif(100*100)
# plot it with the boundaries we want to clip against:
#plot(r)
plot(ne,add=TRUE)
# now use the mask function
#rr <- mask(r, ne)
# plot, and overlay:
#plot(rr);plot(ne,add=TRUE)
library(raster)
# use state bounds from gadm website:
# us = shapefile("USA_adm1.shp")
us <- getData("GADM", country="USA", level=1)
# extract states (need to uppercase everything)
nestates <- c("Maine", "Vermont", "Massachusetts", "New Hampshire" ,"Connecticut",
"Rhode Island")
ne = us[match(toupper(nestates),toupper(us$NAME_1)),]
points(gspecies, col="darkolivegreen4", pch=20, cex=0.5)
# create a random raster over the space:
#r = raster(xmn=-85,xmx=-65,ymn=36,ymx=48,nrow=100,ncol=100)
#r[]=runif(100*100)
# plot it with the boundaries we want to clip against:
#plot(r)
plot(ne,add=TRUE)
# now use the mask function
#rr <- mask(r, ne)
# plot, and overlay:
#plot(rr);plot(ne,add=TRUE)
library(raster)
# use state bounds from gadm website:
# us = shapefile("USA_adm1.shp")
us <- getData("GADM", country="USA", level=1)
# extract states (need to uppercase everything)
nestates <- c("Maine", "Vermont", "Massachusetts", "New Hampshire" ,"Connecticut",
"Rhode Island")
ne = us[match(toupper(nestates),toupper(us$NAME_1)),]
plot(ne,add=TRUE)
plot(ne)
points(gspecies, col="darkolivegreen4", pch=20, cex=0.5)
View(gspecies)
gspecies[,-1]
View(gspecies)
colnames(gspecies) = c("spcode", "lon","lat")
rm(colnames(gspecies))
gmap('maine', longlat=TRUE)
library(raster)
# use state bounds from gadm website:
# us = shapefile("USA_adm1.shp")
us <- getData("GADM", country="USA", level=1)
# extract states (need to uppercase everything)
nestates <- c("Maine", "Vermont", "New Hampshire" ,"Connecticut",
"Rhode Island")
ne = us[match(toupper(nestates),toupper(us$NAME_1)),]
points(gspecies, col="darkolivegreen4", pch=20, cex=0.5)
# create a random raster over the space:
#r = raster(xmn=-85,xmx=-65,ymn=36,ymx=48,nrow=100,ncol=100)
#r[]=runif(100*100)
# plot it with the boundaries we want to clip against:
#plot(r)
plot(ne)
# now use the mask function
#rr <- mask(r, ne)
# plot, and overlay:
#plot(rr);plot(ne,add=TRUE)
points(gspecies, col="darkolivegreen4", pch=20, cex=0.5)
typeof(nestates)
library(raster)
us <- getData("GADM", country="USA", level=1)
# extract states (need to uppercase everything)
nestates <- c("Maine","Connecticut", "Rhode Island")
ne = us[match(toupper(nestates),toupper(us$NAME_1)),]
points(gspecies, col="darkolivegreen4", pch=20, cex=0.5)
# create a random raster over the space:
#r = raster(xmn=-85,xmx=-65,ymn=36,ymx=48,nrow=100,ncol=100)
#r[]=runif(100*100)
# plot it with the boundaries we want to clip against:
#plot(r)
plot(ne)
# now use the mask function
#rr <- mask(r, ne)
# plot, and overlay:
#plot(rr);plot(ne,add=TRUE)
points(gspecies, col="darkolivegreen4", pch=20, cex=0.5)
typeof(gspecies)
library(raster)
r <- raster(gspecies)
extent(r) <- (0, 1, 0, 1)
min[gspecies[,"lat"]]
min(gspecies[,"lat"])
max(gspecies[,"lat"])
max(gspecies[,"lon"])
min(gspecies[,"lon"])
extent(r) <- (-73.35, -67.55, 41.27, 46.78)
extent(r) <- ('-73.35, -67.55, 41.27, 46.78)
extent(r) <- ('-73.35, -67.55, 41.27, 46.78')
r <- raster(gspecies)
typeof(r)
r
extent(r) <- (-73.35, -67.55, 41.27, 46.78)
extent(r) = (-73.35, -67.55, 41.27, 46.78)
extent(r) = (-73.35 -67.55, 41.27, 46.78)
extent(r) = (-73.35 -67.55 41.27 46.78)
summary(gspecies)
extent(r) <- (-73.35, -67.55, 41.27, 46.78)
extent(r) <- (-73.35 , -67.55 , 41.27 , 46.78)
?extent
extent(r) <- c(-73.35 , -67.55 , 41.27 , 46.78)
r <- writeRaster(r, '/Users/annacalderon/Desktop/gENM/data/gspecies.tiff')
library(raster)
library(raster)
us <- getData("GADM", country="USA", level=1)
# extract states (need to uppercase everything)
nestates <- c("Maine","Connecticut", "Rhode Island")
ne = us[match(toupper(nestates),toupper(us$NAME_1)),]
# points(gspecies, col="darkolivegreen4", pch=20, cex=0.5)
# create a random raster over the space:
r = raster("/Users/annacalderon/Desktop/gENM/data/gspecies.tif")
plot(r)
plot(ne)
rr <- mask(r, ne)
plot(rr);plot(ne,add=TRUE)
ne
coord.ref.(r) <- c(+proj=longlat, +datum=WGS84, +no_defs, +ellps=WGS84, +towgs84=0,0,0 )
coord.ref.(r) <- c("+proj=longlat", "+datum=WGS84", "+no_defs", "+ellps=WGS84", "+towgs84=0,0,0" )
points(gspecies, col="black", pch=20, cex=0.5)
points(gspecies, col="black", pch=20, cex=0.5)
points(gspecies, col="black", pch=20, cex=0.5)
gspecies
prespoints <- read.csv('http://harvardforest.fas.harvard.edu/data/p14/hf147/hf147-13-antData_use4R_snappedToClim.csv')
if (gspecies == ''){gspecies <- "aphrud"}
colnames(prespoints) = c("spcode", "lon","lat")
gspecies <- ''
prespoints <- read.csv('http://harvardforest.fas.harvard.edu/data/p14/hf147/hf147-13-antData_use4R_snappedToClim.csv')
if (gspecies == ''){gspecies <- "aphrud"}
colnames(prespoints) = c("spcode", "lon","lat")
gspecies <- prespoints[grep(gspecies,as.character(prespoints$spcode)),]
gspecies$spcode <- NULL
if (identical(colnames(gspecies),c( "lat", "lon"))){gspecies <- gspecies[,c('lon','lat')]}
if (is.matrix(gspecies) == FALSE){gspecies <- data.matrix(gspecies)}
points(gspecies, col="black", pch=20, cex=0.5)
