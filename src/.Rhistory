knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm")
email = acalderon@ucmerced.edu)
knife <- webprocess(email = 'acalderon@ucmerced.edu')
knife
knife <- webprocess(wait = TRUE)
knife
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(email = 'acalderon@ucmerced.edu')
knife <- webprocess(wait = TRUE)
knife
knife <- webprocess(email = 'acalderon@ucmerced.edu')
knife
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(wait = TRUE)
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
stencil <- webgeom('state::Rhode Island, Massachusetts, Maine, Vermont, Connecticut, New Hampshire')
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
job <- geoknife(stencil, fabric, knife, wait = TRUE, OUTPUT_TYPE="geotiff")
check(job)
download(job, destination = "/Users/annacalderon/Desktop/", overwrite=TRUE)
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(email = 'acalderon@ucmerced.edu')
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future',
variable='tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85',times=c('2014-07-15','2014-07-18'))
stencil <- webgeom('state::Rhode Island, Massachusetts, Maine, Vermont, Connecticut, New Hampshire')
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(wait = TRUE)
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future',
variable='tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85',times=c('2014-07-15','2014-07-18'))
stencil <- webgeom('state::Rhode Island, Massachusetts, Maine, Vermont, Connecticut, New Hampshire')
job <- geoknife(stencil, fabric, knife, wait = TRUE)
download(job, destination = "/Users/annacalderon/Desktop/", overwrite=TRUE)
download(job, destination = "/Users/annacalderon/Desktop", overwrite=TRUE)
check(job)
geom(stencil) <- "derivative:CONUS_States"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Maine", "Vermont", "Connecticut", "New Hampshire")
stencil
geom(stencil) <- "sample:CONUS_Climate_Divisions""
geom(stencil) <- "sample:CONUS_Climate_Divisions")
geom(stencil) <- "sample:CONUS_Climate_Divisions"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Maine", "Vermont", "Connecticut", "New Hampshire")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
geom(stencil) <- "sample:CONUS_Climate_Divisions"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
geom(stencil) <- "sample:CONUS_Climate_Divisions"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Maine")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
geom(stencil) <- "sample:CONUS_Climate_Divisions"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Vermont", "Connecticut")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
values(stencil) <- c("Maine")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
geom(stencil) <- "sample:CONUS_Climate_Divisions")
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Vermont", "Connecticut", "New Hampshire")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
check(job)
data.out <- result(job, with.units=TRUE)
data.out
typeof(data.out)
knife <- webprocess(algorithm = list('OPeNDAP Subset'="gov.usgs.cida.gdp.wps.algorithm.FeatureCoverageOPeNDAPIntersectionAlgorithm"))
fabric <- webdata(url='dods://opendap.larc.nasa.gov/opendap/hyrax/SortByProduct/CERES/EBAF/Surface_Edition2.8/CERES_EBAF-Surface_Edition2.8_200003-201506.nc',
variable="sfc_sw_down_all_mon", #Surface Shortwave Flux Down, Monthly Means, All-Sky conditions
times=c('2014-07-15','2014-07-15'))
stencil <- simplegeom(data.frame('point1' = c(-5,32), 'point2' = c(-90,-78))) # big 'ol chunk 'o data
job <- geoknife(stencil, fabric, knife, wait = TRUE, OUTPUT_TYPE = "geotiff")
file <- download(job, destination = file.path(tempdir(), 'nasa_data.zip'), overwrite=TRUE)
job
file <- download(job, destination = file.path(tempdir(), 'nasa_data.zip'), overwrite=TRUE)
data.out <- result(job, with.units=TRUE)
job <- geoknife(stencil, fabric, knife, wait = TRUE)
library(geoknife)
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(wait = TRUE)
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future',
variable='tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85',times=c('2014-07-15','2014-07-18'))
geom(stencil) <- "sample:CONUS_Climate_Divisions")
geom(stencil) <- "sample:CONUS_Climate_Divisions"
geom(stencil) <- "sample:CONUS_Climate_Divisions"
library(geoknife)
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(wait = TRUE)
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future',
variable='tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85',times=c('2014-07-15','2014-07-18'))
geom(stencil) <- "sample:CONUS_Climate_Divisions"
attribute(stencil) <- "STATE"
values(stencil) <- c("Rhode Island", "Massachusetts", "Vermont", "Connecticut", "New Hampshire")
job <- geoknife(stencil, fabric, knife, wait = TRUE)
rm(list=ls())
library(geoknife)
knife <- webprocess(algorithm = list('Area Grid Statistics (weighted)'=
"gov.usgs.cida.gdp.wps.algorithm.FeatureWeightedGridStatisticsAlgorithm"))
knife <- webprocess(wait = TRUE)
fabric <- webdata(url='dods://cida.usgs.gov/thredds/dodsC/macav2metdata_daily_future',
variable='tasmax_CSIRO-Mk3-6-0_r1i1p1_rcp85',times=c('2014-07-15','2014-07-18'))
geom(stencil) <- "sample:CONUS_Climate_Divisions"
> library(raster)
str_name <- '/Users/annacalderon/Desktop/gENM/data/
library(raster)
library(raster)
str_name <- '/Users/annacalderon/Desktop/gENM/data/
cida.usgs.gov-thredds-dodsC-macav2metdata_daily_future-2099-07-01-00-00-00.tiff")
)
str_name <- '/Users/annacalderon/Desktop/gENM/data/
cida.usgs.gov-thredds-dodsC-macav2metdata_daily_future-2099-07-01-00-00-00.tiff')
str_name <- '/Users/annacalderon/Desktop/gENM/data/try.tiff"
str_name <- ('/Users/annacalderon/Desktop/gENM/data/try.tiff')
raster(str_name)
herewego <-raster(str_name)
plot(herewego)
wd <- '/Users/annacalderon/Desktop/gENM/src'
setwd(wd)
## Step 1. Source Helpers Script
source("helpers.R")
mintemp.2006  <- raster("../data/01_01_2006.tiff")
mintemp.2050 <- raster("../data/01_01_2050.tiff")
mintemp.2099 <- raster("../data/01_01_2099.tiff")
mintemp_06 <- as(mintemp.2006, 'SpatialGridDataFrame')
mintemp_50 <- as(mintemp.2050, 'SpatialGridDataFrame')
mintemp_99 <- as(mintemp.2099, 'SpatialGridDataFrame')
gsp <-read.csv("../data/RICTMEdukesnantucket.csv")
if (is.matrix(gsp) == FALSE){gsp <- data.matrix(gsp)}
clust <- gClust(x=gsp, vp=mintemp.2006)
out <- gENM(x=gsp, clust=clust, p=mintem_06) #p must be a raster brick!
out <- gENM(x=gsp, clust=clust, p=mintemp_06) #p must be a raster brick!
setwd(wd)
wd <- '/Users/annacalderon/Desktop/gENM/src'
setwd(wd)
## Step 1. Source Helpers Script
source("helpers.R")
mintemp.2006  <- raster("../data/01_01_2006.tiff")
mintemp_06 <- as(mintemp.2006, 'SpatialGridDataFrame')
gsp <-read.csv("../data/RICTMEdukesnantucket.csv")
if (is.matrix(gsp) == FALSE){gsp <- data.matrix(gsp)}
clust <- gClust(x=gsp, vp=mintemp.2006)
x=gsp
p=mintemp_06
c.rad=50000
seed=123
n=1000
set.seed(seed)
circ <- circles(x, d=c.rad, lonlat=T)
random <- spsample(circ@polygons, n, type='random', iter=100)
gsp_bc <-  extract(p, x)
gsp_bc <- extract(mintemp.2006, x)
gsp_bc <-  data.frame(cbind(x,gsp_bc))
random_bc <- extract(mintemp.2006, random)
random  <- random@coords
colnames(random) <- c("lon","lat")
random_bc <-  data.frame(cbind(random,random_bc))
random_bc  <-  random_bc[!is.na(random_bc[,3]), ]
me <- maxent(mintemp_06, gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")])
e <- evaluate(gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")], me, p)
plot(me)
neClim <- stack("../data/neClim.grd")
me <- maxent(neClim, gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")])
me <- maxent(mintemp_06, gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")])
mintemp_06
neClim[[6]]
neClim
typeof(mintemp_06)
typeof(neClim)
summary(mintemp_06)
me <- maxent(mintemp_06, gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")])
me
plot(me)
plot(mintemp.2006)
plot(mintemp_06)
?maxent
typeof(mintemp_06)
typeof(mintemp.06)
mintemp.2006  <- raster("../data/01_01_2006.tiff")
typeof(mintemp.2006)
mintemp.2006
mintemp_06
?evaluate
mode(mintemp_06)
mode(mintemp.2006)
class(mintemp_06)
class(mintemp.2006)
?evalute
?evaluate
evaluate(model = me)
gsp_bc[,c("lon", "lat")]
e <- evaluate(gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")], me, p)
p
)
p
e <- evaluate(gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")], me)
me
random_bc[,c("lon", "lat")]
gsp_bc[,c("lon", "lat")]
p
p = mintemp_06
p
p = mintemp.2006
p
e <- evaluate(gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")], me, p)
p = mintemp_06
e <- evaluate(gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")], me, p)
p = mintemp_06
e <- evaluate(gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")], me, p)
p = mintemp.2006
e <- evaluate(gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")], me, p)
gsp_bc[,c("lon", "lat")]
random_bc[,c("lon", "lat")]
p
packs <- c("gdistance", "fossil" , "igraph", "rgbif","mapproj","mapdata","sp",
"maptools","dismo","rJava","rgdal", "rgeos", "raster", "FedData")
lapply(packs[!(packs %in% installed.packages()[,'Package'])],install.packages)
all(unlist(lapply(packs, require, character.only = TRUE,quietly=TRUE)))
### Creates a symmetric matrix comprised of
### the sum of the upper and lower triangles.
### MKLau - 06July2016
symSum <- function(x='matrix',zero.diag=TRUE){
if (zero.diag == TRUE){diag(x) <- 0}
sum.lu <- t(x)[lower.tri(x)]  + x[lower.tri(x)]
x[lower.tri(x)] <- sum.lu
x <- t(x)
x[lower.tri(x)] <- sum.lu
if (isSymmetric(x)){x}else{
warning('Output matrix is not symmetirc.')
}
}
###
altDiff <- function(x){x[2] - x[1]}
###
m <- function(scd){(1-(scd/max(scd)))}
###
### gClust - models genetic clusters based on landscape features using circuit
### theory based landscape resistance. Returns a list of observation matrices
### grouped by the 'genetic' clusters.
### MKLau and ACalderon - Summer 2016
### x = Distribution data for a given organism using lon and lat coordinates.
### p = Environmental
### N = effective population size
gClust <- function(x='coordinates',vp='vector predictor',N=1){
# Conductance matrix  used to produce
# an initial matrix of "flow" between observations
if (!(is.matrix(x))){x <- as.matrix(x)}
hd <- transition(vp, altDiff, 8, symm=FALSE)
slope <- geoCorrection(hd)
adj <- adjacent(vp, cells=1:ncell(vp), pairs=TRUE, directions=8)
speed <- slope
speed[adj] <- 6 * exp(-3.5 * abs(slope[adj] + 0.05))
Conductance <- geoCorrection(speed)
cd <- costDistance(Conductance, x)
# Summing over assymmetry
scd <- symSum(cd)
# Re-scaling using basic population
# demography to approximate migration.
# N = effective population size, by
# default this is set to one for mathematical
# convenience. The diagonal is set to zero
# because each observation should be
# genetically identical to itself.
# See Conner & Hartl pg. 84
Fst <- 0.20*(1/(1+4*N*m(scd)))
diag(Fst) <- 0
# Invert Fst so that it is a similarity rather
# than a dissimilarity matrix and find
# the minimally connected graph to focus
# on the most important connections.
Fst.g <- 1  - Fst
diag(Fst.g) <- 0
Fst.mg <- dino.mst(Fst.g)
Fst.ig <- graph.adjacency(Fst.mg,weighted=TRUE,mode='undirected')
# Determine clusters using a graph theoretic
# module/cluster detection algorithm.
fg.mP <- fastgreedy.community(Fst.ig)
gc <- fg.mP$membership
names(gc) <- rownames(Fst)
# Output observations in a format for the
# gENM.
return(gc)
}
######
### Creates an environmental niche model
### based on MaxEnt alogrithims
### to predict habitat suitability.
### ACalderon and MKLau - 15July2016
### x = Distribution data for a given organism using lon and lat coordinates.
### p = Environmental predictor
ENM <- function(x="coordinates", p="predictors",c.rad=50000,seed=123,n=1000){
set.seed(seed)
circ <- circles(x, d=c.rad, lonlat=T)
random <- spsample(circ@polygons, n, type='random', iter=100)
# Makes circles with a 5K radius of each
# point and adds 1000 randomized points.
gsp_bc <-  extract(p, x)
gsp_bc <-  data.frame(cbind(x,gsp_bc))
# Extracts the climate variables which
# correspond to each presence point
# of a cluster. Binds climate variables
# with their resepctive coordinates,
# then turns that matrix into a list.
# And renames the columnames as
# "lon", "lat", and "clim.var"
random_bc <- extract(p, random)
random  <- random@coords
colnames(random) <- c("lon","lat")
# Extracts the climate variables which
# which correspond to each random point
# of a cluster. Coordinates of random are
# saved as a matrix.
random_bc <-  data.frame(cbind(random,random_bc))
random_bc  <-  random_bc[!is.na(random_bc[,3]), ]
# Binds the random point coordinates and
# and the extracted climate variables
# that correspond to those random points
# in order to create a list.
# And renames the columnames as
# "lon", "lat", and "clim.var"
# Also removes any NAs in the list.
me <- maxent(p, gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")])
e <- evaluate(gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")], me, p)
pred_me <- predict(me, p)
# Build a "MaxEnt" (Maximum Entropy) species
# distribution model based on predictors
# and produces a model that is used by
# the predict() fucntion to predict
# the suitability of other locations.
out <- list(eval = e, pred = pred_me, model = me)
return(out)
}
########
### Applies an environmental niche model
### to clusters of a population as well
### as to the entire species, and predicts
### habitat suitability for each cluster.
### ACalderon and MKLau - 15July2016
### x = Distribution data for a given organism using lon and lat coordinates.
### clust = genetic clusters simulated from the gClust function
gENM <- function(x='coordinates', clust='gen clusters', p="Environmental"){
df.gsp <- data.frame(x)
groups <-  split(df.gsp, clust)
analysis <- (lapply(groups, ENM, p))
enm.all <- list(ENM(do.call(rbind,groups),p))
out <- append(enm.all, analysis)
}
########
### Applies an environmental niche model
### to clusters of a population as well
### as to the entire species, and predicts
### habitat suitability for each cluster.
### ACalderon and MKLau - 15July2016
### x = Distribution data for a given organism using lon and lat coordinates.
### clust = genetic clusters simulated from the gClust function
gAnalysis <- function(x="gENM output", filename= "../results/gENM.jpeg",
mfrow=c(3,3),ext=extent(-73.70833, -66.95833, 41, 47.45833),open.file=TRUE){
jpeg(filename = filename, width = 1700, height = 1700,
units = "px", pointsize = 35, quality = 90,
bg="white")
par(mfrow=mfrow, oma=rep(0,4),omi=rep(0,4), bty = 'n',mar=rep(0.01,4),mai=rep(0,4))
for(i in 1: length(x)){zoom(x[[i]]$pred, ext=ext, xaxt='n', yaxt='n', new=FALSE, asp=1)}
dev.off()
auc <- unlist(lapply(x,function(x) x$eval@auc))
cor <- unlist(lapply(x,function(x) x$eval@cor))
out <- data.frame(auc,cor)
return(out)
if (open.file){system(paste('open',filename))}
}
me <- maxent(p, gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")])
me <- maxent(p, gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")])
p
p
mintemp.2006
mintemp_06
p
me <- maxent(p, gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")])
e <- evaluate(gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")], me, p)
p
gsp_bc
p
p@names
names(p)
names(p) <- 'gsp_bc'
me <- maxent(p, gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")])
head(random_bc)
names(gsp_bc)
names(random_bc)
p
colnames(random_bc)[3] <- 'gsp_bc'
me <- maxent(p, gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")])
gsp_bc
random_bc
p
me <- maxent(p, gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")])
random_bc
matrix(random_bc)
random_bc
typeof(random_bc)
?data.matrix
typeof(random_bc)
data.matrix(random_bc)
randombc  <- data.matrix(random_bc)
randombc
typeof(randombc)
randombc[,c('lon','lat')]
x
p
gsp_bc <-  extract(p, x)
gsp_bc <-  data.frame(cbind(x,gsp_bc))
gspbc  <- data.matrix(gsp_bc)
typeof(gspbc)
randombc
me <- maxent(p, gspbc[,c("lon", "lat")], randombc[,c("lon", "lat")])
me <- maxent(p, gsp_bc[,c("lon", "lat")], random_bc[,c("lon", "lat")])
gsp_bc <-  extract(p, x)
random_bc <- extract(p, random)
gsp_bc
head(gsp_bc)
random  <- random@coords
random_bc <- extract(p, random)
random  <- random@coords
random <- spsample(circ@polygons, n, type='random', iter=100)
random_bc <- extract(p, random)
random  <- random@coords
colnames(random) <- c("lon","lat")
colnames(random) <- c("lon","lat")
head(random)
colnames(random_bc)
random_bc <- extract(p, random)
random_bc
random  <- random@coords
random <- spsample(circ@polygons, n, type='random', iter=100)
random  <- random@coords
head(random)
colnames(random) <- c("lon","lat")
random_bc
head(random)
head(random_bc)
?smartbind
mapply(c,x,gsp_bc])
gsp_bc <-  extract(p, x)
gsp_bc
mapply(c,x,gsp_bc)
as.data.frame(mapply(c,x,gsp_bc))
gspbc  <- data.frame(mapply(c(gsp, gsp_bc),SIMPLIFY=F))
gsp
gspbc  <- data.frame(mapply(c(gsp, gsp_bc),SIMPLIFY=F))
gsp_bc
gsp
head(gsp)
colnames(gsp) <- NULL
head(gsp)
data.gram(gsp)
data.frame(gsp)
gsp
head(gsp)
typeof(gsp)
gspe  <- data.frame(gsp)
head(gspe)
typeof(gspe)
colnames(gspe)
colnames(gspe) <- NULL
head(gspe)
gsp
typeof(gsp)
head(gsp)
gsp <-read.csv("../data/RICTMEdukesnantucket.csv")
if (is.matrix(gsp) == FALSE){gsp <- data.matrix(gsp)}
head(gsp)
gsp_bc <-  extract(p, x)
head(gsp_bc)
?melt
names(gsp[[1]])
gsp
names(gsp[,1])
head(gsp)
random
random_bc
typeof(random)
random
randompts <- as.data.frame(random)
randompts
head(randompts)
typeof(randompts)
random <- spsample(circ@polygons, n, type='random', iter=100)
head(random)
random_bc <- extract(p, random)
head(random_bc)
random  <- random@coords
head(random)
typeof(random)
random <- as.data.frame(random)
head(random)
random_bc <-  data.frame(cbind(random,random_bc))
head(random_bc)
typeof(random_bc)
